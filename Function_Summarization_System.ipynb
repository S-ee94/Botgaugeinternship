{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aApH9uwIlxk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Clone the GitHub Repository\n",
        "!git clone https://github.com/S-ee94/My-Projects.git"
      ],
      "metadata": {
        "id": "EzOgyPyjLvVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6f61bf-7133-4ee5-cbed-52f1f403a979"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'My-Projects'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 49 (delta 17), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (49/49), 44.57 MiB | 18.30 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Set up the environment and libraries\n",
        "import os\n",
        "import ast\n",
        "import re\n",
        "import nbformat  # For handling Jupyter Notebooks"
      ],
      "metadata": {
        "id": "J2bZttlNQAAG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Python and Notebook files from the repository\n",
        "def load_code_files(directory):\n",
        "    code_files = []\n",
        "    for subdir, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".py\") or file.endswith(\".ipynb\"):  # Looking for both Python and notebook files\n",
        "                file_path = os.path.join(subdir, file)\n",
        "                code_files.append(file_path)\n",
        "    return code_files"
      ],
      "metadata": {
        "id": "XyXuhgaFQAC6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract code from .ipynb files\n",
        "def extract_code_from_notebook(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        notebook_content = nbformat.read(f, as_version=4)\n",
        "\n",
        "    code = \"\"\n",
        "    for cell in notebook_content['cells']:\n",
        "        if cell['cell_type'] == 'code':  # Extract only code cells\n",
        "            code += cell['source'] + \"\\n\"\n",
        "\n",
        "    print(f\"Extracted code from {file_path}:\\n{code}\\n\")  # Debugging statement to inspect extracted code\n",
        "    return code"
      ],
      "metadata": {
        "id": "UZj2EM3pQAFp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and Summarize Functions using AST\n",
        "def summarize_function(function_node):\n",
        "    # Get function name\n",
        "    func_name = function_node.name\n",
        "\n",
        "    # Get function arguments\n",
        "    args = [arg.arg for arg in function_node.args.args]\n",
        "\n",
        "    # Get docstring if available\n",
        "    docstring = ast.get_docstring(function_node)\n",
        "\n",
        "    # Create a summary\n",
        "    summary = f\"Function `{func_name}` takes arguments {args}. \"\n",
        "    if docstring:\n",
        "        summary += f\"Docstring: {docstring}\"\n",
        "    else:\n",
        "        summary += \"No docstring available.\"\n",
        "\n",
        "    return summary, ast.dump(function_node)"
      ],
      "metadata": {
        "id": "zABCyeHEQAKU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_functions_in_code(file_content):\n",
        "    try:\n",
        "        tree = ast.parse(file_content)\n",
        "    except SyntaxError as e:\n",
        "        print(f\"Syntax error when parsing code: {e}\")\n",
        "        return {}\n",
        "\n",
        "    function_summaries = {}\n",
        "\n",
        "    # Iterate through the AST nodes\n",
        "    for node in ast.walk(tree):\n",
        "        if isinstance(node, ast.FunctionDef):\n",
        "            summary, ast_tree = summarize_function(node)\n",
        "            function_summaries[node.name] = {\"summary\": summary, \"ast\": ast_tree}\n",
        "\n",
        "    return function_summaries"
      ],
      "metadata": {
        "id": "xrETY3dzQANq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Develop Search Mechanism\n",
        "def search_data_type(file_content, data_type):\n",
        "    # Search for the data type using regex\n",
        "    matches = re.findall(r'\\b' + re.escape(data_type) + r'\\b', file_content)\n",
        "    return matches\n",
        "\n",
        "def search_function_usages(file_content, function_name):\n",
        "    # Search for function usage using regex\n",
        "    matches = re.findall(r'\\b' + re.escape(function_name) + r'\\b', file_content)\n",
        "    return matches"
      ],
      "metadata": {
        "id": "FyJ4iqvQQAQw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the Functions to the Repository\n",
        "def summarize_and_search(directory, search_element, search_type=\"data_type\"):\n",
        "    code_files = load_code_files(directory)\n",
        "\n",
        "    if not code_files:\n",
        "        print(f\"No Python or Notebook files found in {directory}\")\n",
        "        return {}, {}\n",
        "\n",
        "    all_summaries = {}\n",
        "    search_results = {}\n",
        "\n",
        "    for file_path in code_files:\n",
        "        print(f\"Processing file: {file_path}\")  # Debugging print statement\n",
        "\n",
        "        if file_path.endswith(\".py\"):\n",
        "            with open(file_path, \"r\") as file:\n",
        "                file_content = file.read()\n",
        "        elif file_path.endswith(\".ipynb\"):\n",
        "            file_content = extract_code_from_notebook(file_path)\n",
        "\n",
        "        file_summaries = summarize_functions_in_code(file_content)\n",
        "        all_summaries[file_path] = file_summaries\n",
        "\n",
        "        if search_type == \"data_type\":\n",
        "            search_results[file_path] = search_data_type(file_content, search_element)\n",
        "        elif search_type == \"function\":\n",
        "            search_results[file_path] = search_function_usages(file_content, search_element)\n",
        "\n",
        "    return all_summaries, search_results"
      ],
      "metadata": {
        "id": "WqWCmnnvQAUl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Run the summarization and search process\n",
        "repository_path = '/content/My-Projects'  # Path to the cloned repository"
      ],
      "metadata": {
        "id": "54VfyinlQAYX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if repository is cloned correctly by listing files\n",
        "!ls $repository_path"
      ],
      "metadata": {
        "id": "DxICkm1SQXqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed35fca-f67a-48b9-fde9-034248070552"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Amazon_SalesData_Analysis.ipynb\t     Movie_Recommender_System.ipynb\n",
            " bot.py\t\t\t\t\t     Object_Detection.ipynb\n",
            "'Data-Preprocessing code.py'\t\t    'PPT Video.mp4'\n",
            "'Deployment code.py'\t\t\t    'Project - Analysis of Amazon Sales Data.pptx'\n",
            "'Final Presentation Template Video.mp4'     'Project - Foreign Direct Investment Analysis.pptx'\n",
            " Foreign_Direct_Investment_Analytics.ipynb   SeemaBS_CV.pdf\n",
            " Manual_Augmentation_new_dataset.ipynb\t     Steel_Rods_Counting_using_yolov8x_Client_Data.ipynb\n",
            " Miscarriage_PPT.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the summarization and search process\n",
        "search_for = \"int\"  # Example: Data type to search for\n",
        "summaries, results = summarize_and_search(repository_path, search_for, search_type=\"data_type\")"
      ],
      "metadata": {
        "id": "k_GR2-LSQXtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac24c605-8dca-4118-a700-6459b9e561f8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/My-Projects/Amazon_SalesData_Analysis.ipynb\n",
            "Extracted code from /content/My-Projects/Amazon_SalesData_Analysis.ipynb:\n",
            "# Importing the necessary libraries\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "\n",
            "# Load the data\n",
            "data = pd.read_csv('/content/Amazon Sales data.csv')\n",
            "data\n",
            "# Data Cleaning\n",
            "data.dropna(inplace=True)  # Example step\n",
            "# Function to parse dates\n",
            "def parse_dates(date):\n",
            "    for fmt in ('%m/%d/%Y', '%d-%m-%Y'):\n",
            "        try:\n",
            "            return pd.to_datetime(date, format=fmt)\n",
            "        except ValueError:\n",
            "            continue\n",
            "    raise ValueError(f\"No valid date format found for {date}\")\n",
            "# Data tranformation\n",
            "data['Order Date'] = data['Order Date'].apply(parse_dates)\n",
            "data['Month'] = data['Order Date'].dt.month\n",
            "data['Year'] = data['Order Date'].dt.year\n",
            "# Calculate monthly sales\n",
            "monthly_sales = data.groupby('Month')['Total Revenue'].sum().reset_index()\n",
            "\n",
            "# Plot monthly sales trend\n",
            "plt.figure(figsize=(10, 6))\n",
            "sns.lineplot(data=monthly_sales, x='Month', y='Total Revenue', marker='o')\n",
            "plt.title('Monthly Sales Trend')\n",
            "plt.xlabel('Month')\n",
            "plt.ylabel('Total Revenue')\n",
            "plt.xticks(range(1, 13))\n",
            "plt.grid(True)\n",
            "plt.show()\n",
            "# Calculate yearly sales\n",
            "yearly_sales = data.groupby('Year')['Total Revenue'].sum().reset_index()\n",
            "\n",
            "# Plot monthly sales trend\n",
            "plt.figure(figsize=(10, 6))\n",
            "sns.lineplot(data=yearly_sales, x='Year', y='Total Revenue', marker='o')\n",
            "plt.title('Yearly Sales Trend')\n",
            "plt.xlabel('Year')\n",
            "plt.ylabel('Total Revenue')\n",
            "plt.grid(True)\n",
            "plt.show()\n",
            "# Calculate yearly_month_wise sales\n",
            "yearly_month_wise_sales = data.groupby(['Year', 'Month'])['Total Revenue'].sum().reset_index()\n",
            "\n",
            "# Plot monthly sales trend\n",
            "plt.figure(figsize=(10, 6))\n",
            "sns.lineplot(data=yearly_month_wise_sales, x='Month', y='Total Revenue', hue='Year')\n",
            "plt.title('Yearly Monthwise Sales Trend')\n",
            "plt.xlabel('Month')\n",
            "plt.ylabel('Total Revenue')\n",
            "plt.grid(True)\n",
            "plt.show()\n",
            "# Key Metrics Calculation\n",
            "total_sales = data['Total Revenue'].sum()\n",
            "average_sales = data['Total Revenue'].mean()\n",
            "# Find Relationships between attributes\n",
            "sns.pairplot(data)\n",
            "plt.show()\n",
            "# Visualization Insights\n",
            "'''\n",
            "Analysis based on the pairplot visualization.\n",
            "\n",
            "Units Sold attribute is slightly positively correlated to Total Revenue, Total Cost and Total Profit.\n",
            "\n",
            "Unit Price is positively correlated to Unit Cost and slightly positively correlated to Total Revenue, Total Cost and Total Profit.\n",
            "\n",
            "Unit Cost is positively correlated to Unit Cost and slightly positively correlated to Total Revenue, Total Cost and Total Profit.\n",
            "\n",
            "Total Revenue is positively correlated to Total Cost and Total Profit and slightly positively correlated to Units Sold, Unit Price, Unit Cost.\n",
            "\n",
            "Total Cost is positively correlated to Total Revenue, Total Profit and slightly positively correlated to Units Sold, Unit Price, Unit Cost.\n",
            "\n",
            "Total Profit is positively correlated to Total Revenue, Units Sold, Total Cost.\n",
            "\n",
            "Month and the Year columns have no correlation with any other columns.\n",
            "\n",
            "\n",
            "Monthly Sales Analysis -> Based on the monthly sales trend, the sales are good initially during January and are at peak in July, but are at the lowest at December.\n",
            "\n",
            "Yearly Sales Analysis -> Based on the yearly sales trend, the sales are at a medium level in the year 2010, they are at peak in the year and are at the lowest in 2017.\n",
            "\n",
            "Yearly Monthwise Sales Analysis -> Based on the yearly monthwise sales trend, during the years 2011 and 2017, during August and October, the sales are at peak. Whereas, in the years\n",
            "2014 and 2017, during the months November and December, the sales are at the least.\n",
            "\n",
            "Note: The bar plots means completely correlated to each other. For example, Year to Year.\n",
            "'''\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing file: /content/My-Projects/Data-Preprocessing code.py\n",
            "Syntax error when parsing code: (unicode error) 'unicodeescape' codec can't decode bytes in position 51-52: truncated \\UXXXXXXXX escape (<unknown>, line 73)\n",
            "Processing file: /content/My-Projects/Steel_Rods_Counting_using_yolov8x_Client_Data.ipynb\n",
            "Extracted code from /content/My-Projects/Steel_Rods_Counting_using_yolov8x_Client_Data.ipynb:\n",
            "import os\n",
            "HOME = os.getcwd()\n",
            "print(HOME)\n",
            "!pip install ultralytics==8.0.134\n",
            "!pip install -U ultralytics\n",
            "\n",
            "from IPython import display\n",
            "display.clear_output()\n",
            "!yolo mode=checks\n",
            "from ultralytics import YOLO\n",
            "from IPython.display import display, Image\n",
            "!pip install roboflow --quiet\n",
            "!pip install Pillow\n",
            "\n",
            "from roboflow import Roboflow\n",
            "rf = Roboflow(api_key=\"eSY6Bks0HNmuOCGSdmrn\")\n",
            "project = rf.workspace(\"intelligent-bar-counting-cqz8y\").project(\"steel-rods-annotation\")\n",
            "dataset = project.version(33).download(\"yolov8\")\n",
            "%cd {HOME}\n",
            "!yolo task=detect mode=train model=yolov8x.pt data={dataset.location}/data.yaml epochs=5 imgsz=500\n",
            "# checking for trained results in train\n",
            "\n",
            "!ls {HOME}/runs/detect/train2/\n",
            "# plotting confusion matrix\n",
            "\n",
            "%cd {HOME}\n",
            "Image(filename=f'{HOME}/runs/detect/train2/confusion_matrix.png', width=800)\n",
            "# Obtaining the train2 results\n",
            "%cd {HOME}\n",
            "Image(filename=f'{HOME}/runs/detect/train2/results.png', width=800)\n",
            "# checking the train_batch2.jpg\n",
            "%cd {HOME}\n",
            "Image(filename=f'{HOME}/runs/detect/train2/train_batch2.jpg', width=800)\n",
            "# Checking the val_batch2_pred.jpg\n",
            "%cd {HOME}\n",
            "Image(filename=f'{HOME}/runs/detect/train2/val_batch2_pred.jpg', width=800)\n",
            "#validating the model using the test set\n",
            "%cd {HOME}\n",
            "!yolo task=detect mode=val model={HOME}/runs/detect/train2/weights/best.pt data={dataset.location}/data.yaml\n",
            "#Inference with custom model/ prediction\n",
            "%cd {HOME}\n",
            "!yolo task=detect mode=predict model={HOME}/runs/detect/train2/weights/best.pt conf=0.25 source={dataset.location}/test/images\n",
            "# Getting the Predicted image\n",
            "\n",
            "import glob\n",
            "from IPython.display import Image, display\n",
            "\n",
            "for image_path in glob.glob(f'{HOME}/runs/detect/predict/*.jpg')[-20:]:\n",
            "         display(Image(filename=image_path, width=600))\n",
            "         print(\"\\n\")\n",
            "!zip -r /content/file.zip /content/runs\n",
            "\n",
            "\n",
            "Syntax error when parsing code: invalid syntax (<unknown>, line 4)\n",
            "Processing file: /content/My-Projects/Deployment code.py\n",
            "Processing file: /content/My-Projects/bot.py\n",
            "Processing file: /content/My-Projects/Object_Detection.ipynb\n",
            "Extracted code from /content/My-Projects/Object_Detection.ipynb:\n",
            "# Install necessary libraries\n",
            "!pip install opencv-python\n",
            "!pip install opencv-python-headless\n",
            "!pip install torch\n",
            "!pip install torchvision\n",
            "# Import necessary libraries\n",
            "import cv2\n",
            "import numpy as np\n",
            "import torch\n",
            "import torchvision\n",
            "from torchvision import transforms\n",
            "# Load YOLO model from torchvision\n",
            "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
            "model.eval()\n",
            "# Function to load and prepare the image\n",
            "def load_image(image_path):\n",
            "    image = cv2.imread(image_path)\n",
            "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
            "    transform = transforms.Compose([\n",
            "        transforms.ToTensor(),\n",
            "    ])\n",
            "    image_tensor = transform(image_rgb)\n",
            "    return image, image_tensor\n",
            "# Function to perform object detection and count labels\n",
            "def detect_and_count(image_path):\n",
            "    image, image_tensor = load_image(image_path)\n",
            "    with torch.no_grad():\n",
            "        predictions = model([image_tensor])[0]\n",
            "\n",
            "    labels = predictions['labels'].numpy()\n",
            "    boxes = predictions['boxes'].detach().numpy()\n",
            "    scores = predictions['scores'].detach().numpy()\n",
            "\n",
            "    # Draw bounding boxes and labels on the image\n",
            "    count = {}\n",
            "    for label, box, score in zip(labels, boxes, scores):\n",
            "        if score > 0.5:  # Considering only detections with confidence score > 0.5\n",
            "            label_name = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
            "            count[label_name] = count.get(label_name, 0) + 1\n",
            "\n",
            "            cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
            "            cv2.putText(image, label_name, (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
            "\n",
            "    # Save the output image\n",
            "    output_image_path = \"output.jpg\"\n",
            "    cv2.imwrite(output_image_path, image)\n",
            "\n",
            "    return output_image_path, count\n",
            "# Define COCO labels\n",
            "COCO_INSTANCE_CATEGORY_NAMES = [\n",
            "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
            "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
            "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A',\n",
            "    'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
            "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
            "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
            "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
            "    'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
            "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock',\n",
            "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
            "]\n",
            "\n",
            "# Path to the input image\n",
            "image_path = '/content/img 5.jpg'\n",
            "\n",
            "# Perform detection and count labels\n",
            "output_image_path, label_count = detect_and_count(image_path)\n",
            "\n",
            "# Display the output image and label count\n",
            "from IPython.display import Image, display\n",
            "display(Image(output_image_path))\n",
            "\n",
            "print(\"Label count:\")\n",
            "for label, count in label_count.items():\n",
            "    print(f\"{label}: {count}\")\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Syntax error when parsing code: invalid syntax (<unknown>, line 2)\n",
            "Processing file: /content/My-Projects/Manual_Augmentation_new_dataset.ipynb\n",
            "Extracted code from /content/My-Projects/Manual_Augmentation_new_dataset.ipynb:\n",
            "import os\n",
            "HOME = os.getcwd()\n",
            "print(HOME)\n",
            "import os\n",
            "import random\n",
            "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
            "import cv2\n",
            "import numpy as np\n",
            "import shutil, sys\n",
            "\n",
            "def copy_txt_file(input_file, output_file):\n",
            "    \"\"\"\n",
            "    Copies the content of the input text file to the output text file.\n",
            "    \"\"\"\n",
            "    shutil.copyfile(input_file, output_file)\n",
            "\n",
            "def upside_down_augmentation(input_image_jpg, input_text_txt, output_image_path, output_text_path):\n",
            "    \"\"\"\n",
            "    Upside-down augmentation: flips the image and updates the bounding box coordinates accordingly.\n",
            "    \"\"\"\n",
            "    # Load the bounding box coordinates from the text file\n",
            "    with open(input_text_txt, 'r') as file:\n",
            "        lines = file.readlines()\n",
            "\n",
            "    # Load the original image\n",
            "    img = Image.open(input_image_jpg)\n",
            "\n",
            "    # Rotate the image and update bounding box coordinates\n",
            "    img_rotated = img.transpose(method=Image.FLIP_TOP_BOTTOM)\n",
            "    updated_lines = []\n",
            "\n",
            "    for line in lines:\n",
            "        label_data = line.split()\n",
            "        x_center = float(label_data[1])\n",
            "        y_center = float(label_data[2])\n",
            "        box_width = float(label_data[3])\n",
            "        box_height = float(label_data[4])\n",
            "\n",
            "        # Calculate the original bounding box coordinates\n",
            "        x_min = int((x_center - box_width / 2) * img.width)\n",
            "        y_min = int((y_center - box_height / 2) * img.height)\n",
            "        x_max = int((x_center + box_width / 2) * img.width)\n",
            "        y_max = int((y_center + box_height / 2) * img.height)\n",
            "\n",
            "        # Update the bounding box coordinates by flipping\n",
            "        updated_y_min = img.height - y_max\n",
            "        updated_y_max = img.height - y_min\n",
            "\n",
            "        # Calculate the updated centered coordinates and dimensions\n",
            "        updated_x_center = (x_min + x_max) / (2 * img.width)\n",
            "        updated_y_center = (updated_y_min + updated_y_max) / (2 * img.height)\n",
            "        updated_width = (x_max - x_min) / img.width\n",
            "        updated_height = (updated_y_max - updated_y_min) / img.height\n",
            "\n",
            "        # Create the updated line\n",
            "        updated_line = f\"{label_data[0]} {updated_x_center} {updated_y_center} {updated_width} {updated_height}\\n\"\n",
            "        updated_lines.append(updated_line)\n",
            "\n",
            "    # Save the rotated image and updated text file\n",
            "    img_rotated.save(output_image_path)\n",
            "    with open(output_text_path, 'w') as file:\n",
            "        file.writelines(updated_lines)\n",
            "\n",
            "def left_right_augmentation(input_image_jpg, input_text_txt, output_image_path, output_text_path):\n",
            "    \"\"\"\n",
            "    Left-right augmentation: flips the image horizontally and updates the bounding box coordinates accordingly.\n",
            "    \"\"\"\n",
            "    # Load the bounding box coordinates from the text file\n",
            "    with open(input_text_txt, 'r') as file:\n",
            "        lines = file.readlines()\n",
            "\n",
            "    # Load the original image\n",
            "    img = Image.open(input_image_jpg)\n",
            "\n",
            "    # Rotate the image and update bounding box coordinates\n",
            "    img_rotated = img.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
            "    updated_lines = []\n",
            "\n",
            "    for line in lines:\n",
            "        label_data = line.split()\n",
            "        x_center = float(label_data[1])\n",
            "        y_center = float(label_data[2])\n",
            "        box_width = float(label_data[3])\n",
            "        box_height = float(label_data[4])\n",
            "\n",
            "        # Calculate the original bounding box coordinates\n",
            "        x_min = int((x_center - box_width / 2) * img.width)\n",
            "        y_min = int((y_center - box_height / 2) * img.height)\n",
            "        x_max = int((x_center + box_width / 2) * img.width)\n",
            "        y_max = int((y_center + box_height / 2) * img.height)\n",
            "\n",
            "        # Update the bounding box coordinates by flipping\n",
            "        updated_x_min = img.width - x_max\n",
            "        updated_x_max = img.width - x_min\n",
            "\n",
            "        # Calculate the updated centroid coordinates and dimensions\n",
            "        updated_x_center = (updated_x_min + updated_x_max) / (2 * img.width)\n",
            "        updated_y_center = y_center\n",
            "        updated_width = (updated_x_max - updated_x_min) / img.width\n",
            "        updated_height = box_height\n",
            "\n",
            "        # Create the updated line\n",
            "        updated_line = f\"{label_data[0]} {updated_x_center} {updated_y_center} {updated_width} {updated_height}\\n\"\n",
            "        updated_lines.append(updated_line)\n",
            "\n",
            "    # Save the rotated image and updated text file\n",
            "    img_rotated.save(output_image_path)\n",
            "    with open(output_text_path, 'w') as file:\n",
            "        file.writelines(updated_lines)\n",
            "\n",
            "def add_noise(img):\n",
            "    \"\"\"\n",
            "    Adds random noise to the image.\n",
            "    \"\"\"\n",
            "    np_img = np.array(img)\n",
            "    noise = np.random.randint(0, 50, size=np_img.shape, dtype=np.uint8)\n",
            "    noisy_img = np.clip(np_img + noise, 0, 255).astype(np.uint8)\n",
            "    return Image.fromarray(noisy_img)\n",
            "\n",
            "def convert_to_grayscale(img):\n",
            "    \"\"\"\n",
            "    Converts the image to grayscale.\n",
            "    \"\"\"\n",
            "    return img.convert('L')\n",
            "\n",
            "def adjust_saturation(img, factor):\n",
            "    \"\"\"\n",
            "    Adjusts the saturation of the image.\n",
            "    \"\"\"\n",
            "    enhancer = ImageEnhance.Color(img)\n",
            "    enhanced_img = enhancer.enhance(factor)\n",
            "    return enhanced_img\n",
            "\n",
            "def adjust_brightness(img, factor):\n",
            "    \"\"\"\n",
            "    Adjusts the brightness of the image.\n",
            "    \"\"\"\n",
            "    enhancer = ImageEnhance.Brightness(img)\n",
            "    enhanced_img = enhancer.enhance(factor)\n",
            "    return enhanced_img\n",
            "\n",
            "def adjust_contrast(img, factor):\n",
            "    \"\"\"\n",
            "    Adjusts the contrast of the image.\n",
            "    \"\"\"\n",
            "    enhancer = ImageEnhance.Contrast(img)\n",
            "    enhanced_img = enhancer.enhance(factor)\n",
            "    return enhanced_img\n",
            "\n",
            "def invert_colors(img):\n",
            "    \"\"\"\n",
            "    Inverts the colors of the image.\n",
            "    \"\"\"\n",
            "    return ImageOps.invert(img)\n",
            "\n",
            "def apply_canny_edge_detection(img):\n",
            "    \"\"\"\n",
            "    Applies Canny edge detection to the image.\n",
            "    \"\"\"\n",
            "    img_gray = img.convert('L')\n",
            "    img_canny = img_gray.filter(ImageFilter.FIND_EDGES)\n",
            "    return img_canny\n",
            "\n",
            "def apply_blur(img):\n",
            "    \"\"\"\n",
            "    Applies blur to the image.\n",
            "    \"\"\"\n",
            "    return img.filter(ImageFilter.BLUR)\n",
            "\n",
            "def create_augmented_images(image_directory, text_directory, output_image_directory, output_text_directory, num_images_per_input=30):\n",
            "    \"\"\"\n",
            "    Creates augmented images for each input image in the image directory and saves them in the output directories.\n",
            "    \"\"\"\n",
            "    # Get the list of input image files\n",
            "    image_files = os.listdir(image_directory)\n",
            "    for image_file in image_files:\n",
            "        # Construct the input image and text file paths\n",
            "        input_image_jpg = os.path.join(image_directory, image_file)\n",
            "        input_text_txt = os.path.join(text_directory, f\"{os.path.splitext(image_file)[0]}.txt\")\n",
            "\n",
            "        # Load the original image\n",
            "        img = Image.open(input_image_jpg)\n",
            "\n",
            "        # Apply various augmentations to create multiple images\n",
            "        for i in range(num_images_per_input):\n",
            "            # Randomly select an augmentation technique\n",
            "            augmentation_choice = random.choice(['upside_down', 'left_right', 'noise', 'grayscale', 'saturation', 'brightness', 'contrast', 'invert', 'canny_edge', 'blur'])\n",
            "\n",
            "            # Create a unique filename for the augmented image and text file\n",
            "            output_image_path = os.path.join(output_image_directory, f\"{os.path.splitext(image_file)[0]}_{i}.jpg\")\n",
            "            output_text_path = os.path.join(output_text_directory, f\"{os.path.splitext(image_file)[0]}_{i}.txt\")\n",
            "\n",
            "            # Apply the selected augmentation technique\n",
            "            if augmentation_choice == 'upside_down':\n",
            "                upside_down_augmentation(input_image_jpg, input_text_txt, output_image_path, output_text_path)\n",
            "            elif augmentation_choice == 'left_right':\n",
            "                left_right_augmentation(input_image_jpg, input_text_txt, output_image_path, output_text_path)\n",
            "            elif augmentation_choice == 'noise':\n",
            "                augmented_img = add_noise(img)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'grayscale':\n",
            "                augmented_img = convert_to_grayscale(img)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'saturation':\n",
            "                saturation_factor = random.uniform(0.5, 1.5)  # Adjust saturation factor as desired\n",
            "                augmented_img = adjust_saturation(img, saturation_factor)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'brightness':\n",
            "                brightness_factor = random.uniform(0.5, 1.5)  # Adjust brightness factor as desired\n",
            "                augmented_img = adjust_brightness(img, brightness_factor)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'contrast':\n",
            "                contrast_factor = random.uniform(0.5, 1.5)  # Adjust contrast factor as desired\n",
            "                augmented_img = adjust_contrast(img, contrast_factor)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'invert':\n",
            "                augmented_img = invert_colors(img)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'canny_edge':\n",
            "                augmented_img = apply_canny_edge_detection(img)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "            elif augmentation_choice == 'blur':\n",
            "                augmented_img = apply_blur(img)\n",
            "                augmented_img.save(output_image_path)\n",
            "                copy_txt_file(input_text_txt, output_text_path)\n",
            "\n",
            "\n",
            "\n",
            "# Example usage\n",
            "image_directory = '/content/drive/MyDrive/Manual Augmentation/Annotated_Images'\n",
            "text_directory = '/content/drive/MyDrive/Manual Augmentation/Annotated_Labels'\n",
            "output_image_directory = '/content/drive/MyDrive/Manual Augmentation/Augmentated_Images'\n",
            "output_text_directory = '/content/drive/MyDrive/Manual Augmentation/Augmentated_Text_Files'\n",
            "\n",
            "# Create the output directories if they don't exist\n",
            "os.makedirs(output_image_directory, exist_ok=True)\n",
            "os.makedirs(output_text_directory, exist_ok=True)\n",
            "\n",
            "# Create augmented images for each input image in the image directory\n",
            "create_augmented_images(image_directory, text_directory, output_image_directory, output_text_directory)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing file: /content/My-Projects/Foreign_Direct_Investment_Analytics.ipynb\n",
            "Extracted code from /content/My-Projects/Foreign_Direct_Investment_Analytics.ipynb:\n",
            "# Importing the necessary libraries\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "# Load the data\n",
            "df = pd.read_csv('/content/FDI data.csv')\n",
            "df\n",
            "# Data Cleaning and Preprocessing\n",
            "print(df.isnull().sum())\n",
            "df = df.dropna()\n",
            "print(df.dtypes)\n",
            "df.columns\n",
            "# Exploratory Data Analysis (EDA)\n",
            "#Sector-wise investment analysis\n",
            "# Melt the dataframe to have 'Year' and 'Amount' columns\n",
            "df_melted = df.melt(id_vars=[\"Sector\"], var_name=\"Year\", value_name=\"Amount\")\n",
            "\n",
            "df_melted\n",
            "\n",
            "# Group by sector and sum the investment amounts\n",
            "sector_investment = df_melted.groupby('Sector')['Amount'].sum().reset_index()\n",
            "\n",
            "# Display the result\n",
            "print(sector_investment)\n",
            "# Year-wise investment analysis\n",
            "# Group by year and sum the investment amounts\n",
            "year_investment = df_melted.groupby('Year')['Amount'].sum().reset_index()\n",
            "\n",
            "# Display the result\n",
            "print(year_investment)\n",
            "\n",
            "# Visualization\n",
            "# Sector-wise investment\n",
            "\n",
            "# Sort the data by investment amount\n",
            "sector_investment_sorted = sector_investment.sort_values(by='Amount', ascending=False)\n",
            "\n",
            "# Create a color palette\n",
            "palette = sns.color_palette(\"viridis\", len(sector_investment_sorted))\n",
            "\n",
            "# Create the bar plot\n",
            "plt.figure(figsize=(14, 10))\n",
            "barplot = sns.barplot(\n",
            "    x='Amount',\n",
            "    y='Sector',\n",
            "    data=sector_investment_sorted,\n",
            "    palette=palette\n",
            ")\n",
            "\n",
            "# Add data labels\n",
            "for i in barplot.containers:\n",
            "    barplot.bar_label(i, fmt='%.2f', padding=3)\n",
            "\n",
            "# Set title and labels\n",
            "plt.title('Sector-wise FDI in India', fontsize=16)\n",
            "plt.xlabel('Investment Amount (in million USD)', fontsize=14)\n",
            "plt.ylabel('Sector', fontsize=14)\n",
            "\n",
            "# Display the plot\n",
            "plt.tight_layout()\n",
            "plt.show()\n",
            "# Year-wise investment\n",
            "plt.figure(figsize=(12, 6))\n",
            "sns.lineplot(x='Year', y='Amount', data=year_investment)\n",
            "plt.title('Year-wise FDI in India')\n",
            "plt.xlabel('Year')\n",
            "plt.ylabel('Investment Amount')\n",
            "plt.xticks(rotation=45)\n",
            "plt.show()\n",
            "#Analysis using Line Plot\n",
            "# Line Plot\n",
            "plt.figure(figsize=(16, 12))\n",
            "sns.lineplot(data=df_melted, x='Year', y='Amount', hue='Sector', marker='o')\n",
            "plt.title('Year-wise FDI Trends for Different Sectors', fontsize=16)\n",
            "plt.xlabel('Year', fontsize=14)\n",
            "plt.ylabel('Investment Amount (in million USD)', fontsize=14)\n",
            "plt.xticks(rotation=45)\n",
            "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
            "plt.show()\n",
            "\n",
            "\n",
            "Processing file: /content/My-Projects/Movie_Recommender_System.ipynb\n",
            "Extracted code from /content/My-Projects/Movie_Recommender_System.ipynb:\n",
            "# Installing necessary package\n",
            "!pip install scikit-surprise\n",
            "# importing the libraries\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Loading the datasets\n",
            "df1=pd.read_csv('/content/tmdb_5000_credits.csv')\n",
            "df2=pd.read_csv('/content/tmdb_5000_movies.csv')\n",
            "df1.head()\n",
            "df2.head()\n",
            "\n",
            "# Let's join the two dataset on the 'id' column\n",
            "df1.columns = ['id','tittle','cast','crew']\n",
            "df2= df2.merge(df1,on='id')\n",
            "df2.head()\n",
            "# We already have v(vote_count) and R (vote_average) and C can be calculated as\n",
            "C= df2['vote_average'].mean()\n",
            "C\n",
            "# Calculating the 'm' value as per the formula\n",
            "m= df2['vote_count'].quantile(0.9)\n",
            "m\n",
            "# Now, we can filter out the movies that qualify for the chart\n",
            "q_movies = df2.copy().loc[df2['vote_count'] >= m]\n",
            "q_movies.shape\n",
            "def weighted_rating(x, m=m, C=C):\n",
            "    v = x['vote_count']\n",
            "    R = x['vote_average']\n",
            "    # Calculation based on the IMDB formula\n",
            "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
            "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
            "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
            "#Sort movies based on score calculated above\n",
            "q_movies = q_movies.sort_values('score', ascending=False)\n",
            "\n",
            "#Print the top 15 movies\n",
            "q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)\n",
            "# Finally, We have made our first(though very basic) recommender. Under the Trending Now tab of these systems we find movies\n",
            "# that are very popular and they can just be obtained by sorting the dataset by the popularity column.\n",
            "pop= df2.sort_values('popularity', ascending=False)\n",
            "import matplotlib.pyplot as plt\n",
            "plt.figure(figsize=(12,4))\n",
            "\n",
            "plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',\n",
            "        color='skyblue')\n",
            "plt.gca().invert_yaxis()\n",
            "plt.xlabel(\"Popularity\")\n",
            "plt.title(\"Popular Movies\")\n",
            "df2['overview'].head(5)\n",
            "# Data Preprocessing: TF-IDF\n",
            "#Import TfIdfVectorizer from scikit-learn\n",
            "from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "\n",
            "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
            "tfidf = TfidfVectorizer(stop_words='english')\n",
            "\n",
            "#Replace NaN with an empty string\n",
            "df2['overview'] = df2['overview'].fillna('')\n",
            "\n",
            "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
            "tfidf_matrix = tfidf.fit_transform(df2['overview'])\n",
            "\n",
            "#Output the shape of tfidf_matrix\n",
            "tfidf_matrix.shape\n",
            "# Import linear_kernel\n",
            "from sklearn.metrics.pairwise import linear_kernel\n",
            "\n",
            "# Compute the cosine similarity matrix\n",
            "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
            "#Construct a reverse map of indices and movie titles\n",
            "indices = pd.Series(df2.index, index=df2['title']).drop_duplicates()\n",
            "# Function that takes in movie title as input and outputs most similar movies\n",
            "def get_recommendations(title, cosine_sim=cosine_sim):\n",
            "    # Get the index of the movie that matches the title\n",
            "    idx = indices[title]\n",
            "\n",
            "    # Get the pairwsie similarity scores of all movies with that movie\n",
            "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
            "\n",
            "    # Sort the movies based on the similarity scores\n",
            "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
            "\n",
            "    # Get the scores of the 10 most similar movies\n",
            "    sim_scores = sim_scores[1:11]\n",
            "\n",
            "    # Get the movie indices\n",
            "    movie_indices = [i[0] for i in sim_scores]\n",
            "\n",
            "    # Return the top 10 most similar movies\n",
            "    return df2['title'].iloc[movie_indices]\n",
            "get_recommendations('The Dark Knight Rises')\n",
            "get_recommendations('The Avengers')\n",
            "# Parse the stringified features into their corresponding python objects\n",
            "from ast import literal_eval\n",
            "\n",
            "features = ['cast', 'crew', 'keywords', 'genres']\n",
            "for feature in features:\n",
            "    df2[feature] = df2[feature].apply(literal_eval)\n",
            "# Next, we'll write functions that will help us to extract the required information from each feature.\n",
            "# Get the director's name from the crew feature. If director is not listed, return NaN\n",
            "def get_director(x):\n",
            "    for i in x:\n",
            "        if i['job'] == 'Director':\n",
            "            return i['name']\n",
            "    return np.nan\n",
            "# Returns the list top 3 elements or entire list; whichever is more.\n",
            "def get_list(x):\n",
            "    if isinstance(x, list):\n",
            "        names = [i['name'] for i in x]\n",
            "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
            "        if len(names) > 3:\n",
            "            names = names[:3]\n",
            "        return names\n",
            "\n",
            "    #Return empty list in case of missing/malformed data\n",
            "    return []\n",
            "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
            "df2['director'] = df2['crew'].apply(get_director)\n",
            "\n",
            "features = ['cast', 'keywords', 'genres']\n",
            "for feature in features:\n",
            "    df2[feature] = df2[feature].apply(get_list)\n",
            "# Print the new features of the first 3 films\n",
            "df2[['title', 'cast', 'director', 'keywords', 'genres']].head(3)\n",
            "# Function to convert all strings to lower case and strip names of spaces\n",
            "def clean_data(x):\n",
            "    if isinstance(x, list):\n",
            "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
            "    else:\n",
            "        #Check if director exists. If not, return empty string\n",
            "        if isinstance(x, str):\n",
            "            return str.lower(x.replace(\" \", \"\"))\n",
            "        else:\n",
            "            return ''\n",
            "# Apply clean_data function to your features.\n",
            "features = ['cast', 'keywords', 'director', 'genres']\n",
            "\n",
            "for feature in features:\n",
            "    df2[feature] = df2[feature].apply(clean_data)\n",
            "def create_soup(x):\n",
            "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
            "df2['soup'] = df2.apply(create_soup, axis=1)\n",
            "# Import CountVectorizer and create the count matrix\n",
            "from sklearn.feature_extraction.text import CountVectorizer\n",
            "\n",
            "count = CountVectorizer(stop_words='english')\n",
            "count_matrix = count.fit_transform(df2['soup'])\n",
            "# Compute the Cosine Similarity matrix based on the count_matrix\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "\n",
            "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
            "# Reset index of our main DataFrame and construct reverse mapping as before\n",
            "df2 = df2.reset_index()\n",
            "indices = pd.Series(df2.index, index=df2['title'])\n",
            "# We can now reuse our get_recommendations() function by passing in the new cosine_sim2 matrix as your second argument.\n",
            "get_recommendations('The Dark Knight Rises', cosine_sim2)\n",
            "get_recommendations('The Godfather', cosine_sim2)\n",
            "\n",
            "\n",
            "# Since the dataset we used before did not have userId(which is necessary for collaborative filtering) let's load another dataset.\n",
            "#  We'll be using the Surprise library to implement SVD.\n",
            "# Import cross_validate instead of evaluate # Later, when you need to evaluate a model, use cross_validate like this:\n",
            "# results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
            "from surprise import Reader, Dataset, SVD\n",
            "from surprise.model_selection import cross_validate\n",
            "reader = Reader()\n",
            "ratings = pd.read_csv('/content/ratings_small.csv')\n",
            "ratings.head()\n",
            "\n",
            "# Note that in this dataset movies are rated on a scale of 5 unlike the earlier one.\n",
            "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
            "\n",
            "# Proceed with model training and evaluation using cross_validate\n",
            "algo = SVD()\n",
            "results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
            "# We get a mean Root Mean Sqaure Error of 0.89 approx which is more than good enough for our case.\n",
            "# Let us now train on our dataset and arrive at predictions.\n",
            "\n",
            "trainset = data.build_full_trainset()\n",
            "algo.fit(trainset)\n",
            "# Let us pick user with user Id 1 and check the ratings she/he has given.\n",
            "ratings[ratings['userId'] == 1]\n",
            "# Making predictions\n",
            "algo.predict(1, 302, 3)\n",
            "\n",
            "\n",
            "Syntax error when parsing code: invalid syntax (<unknown>, line 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Print Summaries and Search Results\n",
        "if summaries:\n",
        "    for file_path, summary in summaries.items():\n",
        "        print(f\"File: {file_path}\")\n",
        "        for func_name, func_data in summary.items():\n",
        "            print(f\"\\n{func_name}:\")\n",
        "            print(f\"Summary: {func_data['summary']}\")\n",
        "            print(f\"AST: {func_data['ast']}\")\n",
        "else:\n",
        "    print(\"No function summaries were generated.\")\n",
        "\n",
        "if results:\n",
        "    for file_path, matches in results.items():\n",
        "        print(f\"\\nSearch Results in {file_path}: {matches}\")\n",
        "else:\n",
        "    print(\"No search results found.\")"
      ],
      "metadata": {
        "id": "F-ChrulPQXwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e94d37-83c8-4d15-eb14-30f3e2bca583"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: /content/My-Projects/Amazon_SalesData_Analysis.ipynb\n",
            "\n",
            "parse_dates:\n",
            "Summary: Function `parse_dates` takes arguments ['date']. No docstring available.\n",
            "AST: FunctionDef(name='parse_dates', args=arguments(posonlyargs=[], args=[arg(arg='date')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[For(target=Name(id='fmt', ctx=Store()), iter=Tuple(elts=[Constant(value='%m/%d/%Y'), Constant(value='%d-%m-%Y')], ctx=Load()), body=[Try(body=[Return(value=Call(func=Attribute(value=Name(id='pd', ctx=Load()), attr='to_datetime', ctx=Load()), args=[Name(id='date', ctx=Load())], keywords=[keyword(arg='format', value=Name(id='fmt', ctx=Load()))]))], handlers=[ExceptHandler(type=Name(id='ValueError', ctx=Load()), body=[Continue()])], orelse=[], finalbody=[])], orelse=[]), Raise(exc=Call(func=Name(id='ValueError', ctx=Load()), args=[JoinedStr(values=[Constant(value='No valid date format found for '), FormattedValue(value=Name(id='date', ctx=Load()), conversion=-1)])], keywords=[]))], decorator_list=[])\n",
            "File: /content/My-Projects/Data-Preprocessing code.py\n",
            "File: /content/My-Projects/Steel_Rods_Counting_using_yolov8x_Client_Data.ipynb\n",
            "File: /content/My-Projects/Deployment code.py\n",
            "File: /content/My-Projects/bot.py\n",
            "\n",
            "recognize_speech:\n",
            "Summary: Function `recognize_speech` takes arguments ['audio_data', 'sample_rate', 'sample_width']. No docstring available.\n",
            "AST: FunctionDef(name='recognize_speech', args=arguments(posonlyargs=[], args=[arg(arg='audio_data'), arg(arg='sample_rate'), arg(arg='sample_width')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Assign(targets=[Name(id='recognizer', ctx=Store())], value=Call(func=Attribute(value=Name(id='sr', ctx=Load()), attr='Recognizer', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id='audio', ctx=Store())], value=Call(func=Attribute(value=Name(id='sr', ctx=Load()), attr='AudioData', ctx=Load()), args=[Name(id='audio_data', ctx=Load()), Name(id='sample_rate', ctx=Load()), Name(id='sample_width', ctx=Load())], keywords=[])), Try(body=[Assign(targets=[Name(id='text', ctx=Store())], value=Call(func=Attribute(value=Name(id='recognizer', ctx=Load()), attr='recognize_google', ctx=Load()), args=[Name(id='audio', ctx=Load())], keywords=[])), Return(value=Name(id='text', ctx=Load()))], handlers=[ExceptHandler(type=Attribute(value=Name(id='sr', ctx=Load()), attr='UnknownValueError', ctx=Load()), body=[Return(value=Constant(value='Sorry, I could not understand the audio.'))]), ExceptHandler(type=Attribute(value=Name(id='sr', ctx=Load()), attr='RequestError', ctx=Load()), body=[Return(value=Constant(value='Sorry, the speech recognition service is not available.'))])], orelse=[], finalbody=[])], decorator_list=[])\n",
            "File: /content/My-Projects/Object_Detection.ipynb\n",
            "File: /content/My-Projects/Manual_Augmentation_new_dataset.ipynb\n",
            "\n",
            "copy_txt_file:\n",
            "Summary: Function `copy_txt_file` takes arguments ['input_file', 'output_file']. Docstring: Copies the content of the input text file to the output text file.\n",
            "AST: FunctionDef(name='copy_txt_file', args=arguments(posonlyargs=[], args=[arg(arg='input_file'), arg(arg='output_file')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Copies the content of the input text file to the output text file.\\n    ')), Expr(value=Call(func=Attribute(value=Name(id='shutil', ctx=Load()), attr='copyfile', ctx=Load()), args=[Name(id='input_file', ctx=Load()), Name(id='output_file', ctx=Load())], keywords=[]))], decorator_list=[])\n",
            "\n",
            "upside_down_augmentation:\n",
            "Summary: Function `upside_down_augmentation` takes arguments ['input_image_jpg', 'input_text_txt', 'output_image_path', 'output_text_path']. Docstring: Upside-down augmentation: flips the image and updates the bounding box coordinates accordingly.\n",
            "AST: FunctionDef(name='upside_down_augmentation', args=arguments(posonlyargs=[], args=[arg(arg='input_image_jpg'), arg(arg='input_text_txt'), arg(arg='output_image_path'), arg(arg='output_text_path')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Upside-down augmentation: flips the image and updates the bounding box coordinates accordingly.\\n    ')), With(items=[withitem(context_expr=Call(func=Name(id='open', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Constant(value='r')], keywords=[]), optional_vars=Name(id='file', ctx=Store()))], body=[Assign(targets=[Name(id='lines', ctx=Store())], value=Call(func=Attribute(value=Name(id='file', ctx=Load()), attr='readlines', ctx=Load()), args=[], keywords=[]))]), Assign(targets=[Name(id='img', ctx=Store())], value=Call(func=Attribute(value=Name(id='Image', ctx=Load()), attr='open', ctx=Load()), args=[Name(id='input_image_jpg', ctx=Load())], keywords=[])), Assign(targets=[Name(id='img_rotated', ctx=Store())], value=Call(func=Attribute(value=Name(id='img', ctx=Load()), attr='transpose', ctx=Load()), args=[], keywords=[keyword(arg='method', value=Attribute(value=Name(id='Image', ctx=Load()), attr='FLIP_TOP_BOTTOM', ctx=Load()))])), Assign(targets=[Name(id='updated_lines', ctx=Store())], value=List(elts=[], ctx=Load())), For(target=Name(id='line', ctx=Store()), iter=Name(id='lines', ctx=Load()), body=[Assign(targets=[Name(id='label_data', ctx=Store())], value=Call(func=Attribute(value=Name(id='line', ctx=Load()), attr='split', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id='x_center', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=1), ctx=Load())], keywords=[])), Assign(targets=[Name(id='y_center', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=2), ctx=Load())], keywords=[])), Assign(targets=[Name(id='box_width', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=3), ctx=Load())], keywords=[])), Assign(targets=[Name(id='box_height', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=4), ctx=Load())], keywords=[])), Assign(targets=[Name(id='x_min', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='x_center', ctx=Load()), op=Sub(), right=BinOp(left=Name(id='box_width', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='y_min', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='y_center', ctx=Load()), op=Sub(), right=BinOp(left=Name(id='box_height', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='x_max', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='x_center', ctx=Load()), op=Add(), right=BinOp(left=Name(id='box_width', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='y_max', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='y_center', ctx=Load()), op=Add(), right=BinOp(left=Name(id='box_height', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='updated_y_min', ctx=Store())], value=BinOp(left=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()), op=Sub(), right=Name(id='y_max', ctx=Load()))), Assign(targets=[Name(id='updated_y_max', ctx=Store())], value=BinOp(left=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()), op=Sub(), right=Name(id='y_min', ctx=Load()))), Assign(targets=[Name(id='updated_x_center', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='x_min', ctx=Load()), op=Add(), right=Name(id='x_max', ctx=Load())), op=Div(), right=BinOp(left=Constant(value=2), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load())))), Assign(targets=[Name(id='updated_y_center', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='updated_y_min', ctx=Load()), op=Add(), right=Name(id='updated_y_max', ctx=Load())), op=Div(), right=BinOp(left=Constant(value=2), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load())))), Assign(targets=[Name(id='updated_width', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='x_max', ctx=Load()), op=Sub(), right=Name(id='x_min', ctx=Load())), op=Div(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))), Assign(targets=[Name(id='updated_height', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='updated_y_max', ctx=Load()), op=Sub(), right=Name(id='updated_y_min', ctx=Load())), op=Div(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()))), Assign(targets=[Name(id='updated_line', ctx=Store())], value=JoinedStr(values=[FormattedValue(value=Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=0), ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_x_center', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_y_center', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_width', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_height', ctx=Load()), conversion=-1), Constant(value='\\n')])), Expr(value=Call(func=Attribute(value=Name(id='updated_lines', ctx=Load()), attr='append', ctx=Load()), args=[Name(id='updated_line', ctx=Load())], keywords=[]))], orelse=[]), Expr(value=Call(func=Attribute(value=Name(id='img_rotated', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), With(items=[withitem(context_expr=Call(func=Name(id='open', ctx=Load()), args=[Name(id='output_text_path', ctx=Load()), Constant(value='w')], keywords=[]), optional_vars=Name(id='file', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id='file', ctx=Load()), attr='writelines', ctx=Load()), args=[Name(id='updated_lines', ctx=Load())], keywords=[]))])], decorator_list=[])\n",
            "\n",
            "left_right_augmentation:\n",
            "Summary: Function `left_right_augmentation` takes arguments ['input_image_jpg', 'input_text_txt', 'output_image_path', 'output_text_path']. Docstring: Left-right augmentation: flips the image horizontally and updates the bounding box coordinates accordingly.\n",
            "AST: FunctionDef(name='left_right_augmentation', args=arguments(posonlyargs=[], args=[arg(arg='input_image_jpg'), arg(arg='input_text_txt'), arg(arg='output_image_path'), arg(arg='output_text_path')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Left-right augmentation: flips the image horizontally and updates the bounding box coordinates accordingly.\\n    ')), With(items=[withitem(context_expr=Call(func=Name(id='open', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Constant(value='r')], keywords=[]), optional_vars=Name(id='file', ctx=Store()))], body=[Assign(targets=[Name(id='lines', ctx=Store())], value=Call(func=Attribute(value=Name(id='file', ctx=Load()), attr='readlines', ctx=Load()), args=[], keywords=[]))]), Assign(targets=[Name(id='img', ctx=Store())], value=Call(func=Attribute(value=Name(id='Image', ctx=Load()), attr='open', ctx=Load()), args=[Name(id='input_image_jpg', ctx=Load())], keywords=[])), Assign(targets=[Name(id='img_rotated', ctx=Store())], value=Call(func=Attribute(value=Name(id='img', ctx=Load()), attr='transpose', ctx=Load()), args=[], keywords=[keyword(arg='method', value=Attribute(value=Name(id='Image', ctx=Load()), attr='FLIP_LEFT_RIGHT', ctx=Load()))])), Assign(targets=[Name(id='updated_lines', ctx=Store())], value=List(elts=[], ctx=Load())), For(target=Name(id='line', ctx=Store()), iter=Name(id='lines', ctx=Load()), body=[Assign(targets=[Name(id='label_data', ctx=Store())], value=Call(func=Attribute(value=Name(id='line', ctx=Load()), attr='split', ctx=Load()), args=[], keywords=[])), Assign(targets=[Name(id='x_center', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=1), ctx=Load())], keywords=[])), Assign(targets=[Name(id='y_center', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=2), ctx=Load())], keywords=[])), Assign(targets=[Name(id='box_width', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=3), ctx=Load())], keywords=[])), Assign(targets=[Name(id='box_height', ctx=Store())], value=Call(func=Name(id='float', ctx=Load()), args=[Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=4), ctx=Load())], keywords=[])), Assign(targets=[Name(id='x_min', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='x_center', ctx=Load()), op=Sub(), right=BinOp(left=Name(id='box_width', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='y_min', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='y_center', ctx=Load()), op=Sub(), right=BinOp(left=Name(id='box_height', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='x_max', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='x_center', ctx=Load()), op=Add(), right=BinOp(left=Name(id='box_width', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='y_max', ctx=Store())], value=Call(func=Name(id='int', ctx=Load()), args=[BinOp(left=BinOp(left=Name(id='y_center', ctx=Load()), op=Add(), right=BinOp(left=Name(id='box_height', ctx=Load()), op=Div(), right=Constant(value=2))), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='height', ctx=Load()))], keywords=[])), Assign(targets=[Name(id='updated_x_min', ctx=Store())], value=BinOp(left=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()), op=Sub(), right=Name(id='x_max', ctx=Load()))), Assign(targets=[Name(id='updated_x_max', ctx=Store())], value=BinOp(left=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()), op=Sub(), right=Name(id='x_min', ctx=Load()))), Assign(targets=[Name(id='updated_x_center', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='updated_x_min', ctx=Load()), op=Add(), right=Name(id='updated_x_max', ctx=Load())), op=Div(), right=BinOp(left=Constant(value=2), op=Mult(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load())))), Assign(targets=[Name(id='updated_y_center', ctx=Store())], value=Name(id='y_center', ctx=Load())), Assign(targets=[Name(id='updated_width', ctx=Store())], value=BinOp(left=BinOp(left=Name(id='updated_x_max', ctx=Load()), op=Sub(), right=Name(id='updated_x_min', ctx=Load())), op=Div(), right=Attribute(value=Name(id='img', ctx=Load()), attr='width', ctx=Load()))), Assign(targets=[Name(id='updated_height', ctx=Store())], value=Name(id='box_height', ctx=Load())), Assign(targets=[Name(id='updated_line', ctx=Store())], value=JoinedStr(values=[FormattedValue(value=Subscript(value=Name(id='label_data', ctx=Load()), slice=Constant(value=0), ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_x_center', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_y_center', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_width', ctx=Load()), conversion=-1), Constant(value=' '), FormattedValue(value=Name(id='updated_height', ctx=Load()), conversion=-1), Constant(value='\\n')])), Expr(value=Call(func=Attribute(value=Name(id='updated_lines', ctx=Load()), attr='append', ctx=Load()), args=[Name(id='updated_line', ctx=Load())], keywords=[]))], orelse=[]), Expr(value=Call(func=Attribute(value=Name(id='img_rotated', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), With(items=[withitem(context_expr=Call(func=Name(id='open', ctx=Load()), args=[Name(id='output_text_path', ctx=Load()), Constant(value='w')], keywords=[]), optional_vars=Name(id='file', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id='file', ctx=Load()), attr='writelines', ctx=Load()), args=[Name(id='updated_lines', ctx=Load())], keywords=[]))])], decorator_list=[])\n",
            "\n",
            "add_noise:\n",
            "Summary: Function `add_noise` takes arguments ['img']. Docstring: Adds random noise to the image.\n",
            "AST: FunctionDef(name='add_noise', args=arguments(posonlyargs=[], args=[arg(arg='img')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Adds random noise to the image.\\n    ')), Assign(targets=[Name(id='np_img', ctx=Store())], value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='array', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Assign(targets=[Name(id='noise', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='np', ctx=Load()), attr='random', ctx=Load()), attr='randint', ctx=Load()), args=[Constant(value=0), Constant(value=50)], keywords=[keyword(arg='size', value=Attribute(value=Name(id='np_img', ctx=Load()), attr='shape', ctx=Load())), keyword(arg='dtype', value=Attribute(value=Name(id='np', ctx=Load()), attr='uint8', ctx=Load()))])), Assign(targets=[Name(id='noisy_img', ctx=Store())], value=Call(func=Attribute(value=Call(func=Attribute(value=Name(id='np', ctx=Load()), attr='clip', ctx=Load()), args=[BinOp(left=Name(id='np_img', ctx=Load()), op=Add(), right=Name(id='noise', ctx=Load())), Constant(value=0), Constant(value=255)], keywords=[]), attr='astype', ctx=Load()), args=[Attribute(value=Name(id='np', ctx=Load()), attr='uint8', ctx=Load())], keywords=[])), Return(value=Call(func=Attribute(value=Name(id='Image', ctx=Load()), attr='fromarray', ctx=Load()), args=[Name(id='noisy_img', ctx=Load())], keywords=[]))], decorator_list=[])\n",
            "\n",
            "convert_to_grayscale:\n",
            "Summary: Function `convert_to_grayscale` takes arguments ['img']. Docstring: Converts the image to grayscale.\n",
            "AST: FunctionDef(name='convert_to_grayscale', args=arguments(posonlyargs=[], args=[arg(arg='img')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Converts the image to grayscale.\\n    ')), Return(value=Call(func=Attribute(value=Name(id='img', ctx=Load()), attr='convert', ctx=Load()), args=[Constant(value='L')], keywords=[]))], decorator_list=[])\n",
            "\n",
            "adjust_saturation:\n",
            "Summary: Function `adjust_saturation` takes arguments ['img', 'factor']. Docstring: Adjusts the saturation of the image.\n",
            "AST: FunctionDef(name='adjust_saturation', args=arguments(posonlyargs=[], args=[arg(arg='img'), arg(arg='factor')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Adjusts the saturation of the image.\\n    ')), Assign(targets=[Name(id='enhancer', ctx=Store())], value=Call(func=Attribute(value=Name(id='ImageEnhance', ctx=Load()), attr='Color', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Assign(targets=[Name(id='enhanced_img', ctx=Store())], value=Call(func=Attribute(value=Name(id='enhancer', ctx=Load()), attr='enhance', ctx=Load()), args=[Name(id='factor', ctx=Load())], keywords=[])), Return(value=Name(id='enhanced_img', ctx=Load()))], decorator_list=[])\n",
            "\n",
            "adjust_brightness:\n",
            "Summary: Function `adjust_brightness` takes arguments ['img', 'factor']. Docstring: Adjusts the brightness of the image.\n",
            "AST: FunctionDef(name='adjust_brightness', args=arguments(posonlyargs=[], args=[arg(arg='img'), arg(arg='factor')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Adjusts the brightness of the image.\\n    ')), Assign(targets=[Name(id='enhancer', ctx=Store())], value=Call(func=Attribute(value=Name(id='ImageEnhance', ctx=Load()), attr='Brightness', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Assign(targets=[Name(id='enhanced_img', ctx=Store())], value=Call(func=Attribute(value=Name(id='enhancer', ctx=Load()), attr='enhance', ctx=Load()), args=[Name(id='factor', ctx=Load())], keywords=[])), Return(value=Name(id='enhanced_img', ctx=Load()))], decorator_list=[])\n",
            "\n",
            "adjust_contrast:\n",
            "Summary: Function `adjust_contrast` takes arguments ['img', 'factor']. Docstring: Adjusts the contrast of the image.\n",
            "AST: FunctionDef(name='adjust_contrast', args=arguments(posonlyargs=[], args=[arg(arg='img'), arg(arg='factor')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Adjusts the contrast of the image.\\n    ')), Assign(targets=[Name(id='enhancer', ctx=Store())], value=Call(func=Attribute(value=Name(id='ImageEnhance', ctx=Load()), attr='Contrast', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Assign(targets=[Name(id='enhanced_img', ctx=Store())], value=Call(func=Attribute(value=Name(id='enhancer', ctx=Load()), attr='enhance', ctx=Load()), args=[Name(id='factor', ctx=Load())], keywords=[])), Return(value=Name(id='enhanced_img', ctx=Load()))], decorator_list=[])\n",
            "\n",
            "invert_colors:\n",
            "Summary: Function `invert_colors` takes arguments ['img']. Docstring: Inverts the colors of the image.\n",
            "AST: FunctionDef(name='invert_colors', args=arguments(posonlyargs=[], args=[arg(arg='img')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Inverts the colors of the image.\\n    ')), Return(value=Call(func=Attribute(value=Name(id='ImageOps', ctx=Load()), attr='invert', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[]))], decorator_list=[])\n",
            "\n",
            "apply_canny_edge_detection:\n",
            "Summary: Function `apply_canny_edge_detection` takes arguments ['img']. Docstring: Applies Canny edge detection to the image.\n",
            "AST: FunctionDef(name='apply_canny_edge_detection', args=arguments(posonlyargs=[], args=[arg(arg='img')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Applies Canny edge detection to the image.\\n    ')), Assign(targets=[Name(id='img_gray', ctx=Store())], value=Call(func=Attribute(value=Name(id='img', ctx=Load()), attr='convert', ctx=Load()), args=[Constant(value='L')], keywords=[])), Assign(targets=[Name(id='img_canny', ctx=Store())], value=Call(func=Attribute(value=Name(id='img_gray', ctx=Load()), attr='filter', ctx=Load()), args=[Attribute(value=Name(id='ImageFilter', ctx=Load()), attr='FIND_EDGES', ctx=Load())], keywords=[])), Return(value=Name(id='img_canny', ctx=Load()))], decorator_list=[])\n",
            "\n",
            "apply_blur:\n",
            "Summary: Function `apply_blur` takes arguments ['img']. Docstring: Applies blur to the image.\n",
            "AST: FunctionDef(name='apply_blur', args=arguments(posonlyargs=[], args=[arg(arg='img')], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='\\n    Applies blur to the image.\\n    ')), Return(value=Call(func=Attribute(value=Name(id='img', ctx=Load()), attr='filter', ctx=Load()), args=[Attribute(value=Name(id='ImageFilter', ctx=Load()), attr='BLUR', ctx=Load())], keywords=[]))], decorator_list=[])\n",
            "\n",
            "create_augmented_images:\n",
            "Summary: Function `create_augmented_images` takes arguments ['image_directory', 'text_directory', 'output_image_directory', 'output_text_directory', 'num_images_per_input']. Docstring: Creates augmented images for each input image in the image directory and saves them in the output directories.\n",
            "AST: FunctionDef(name='create_augmented_images', args=arguments(posonlyargs=[], args=[arg(arg='image_directory'), arg(arg='text_directory'), arg(arg='output_image_directory'), arg(arg='output_text_directory'), arg(arg='num_images_per_input')], kwonlyargs=[], kw_defaults=[], defaults=[Constant(value=30)]), body=[Expr(value=Constant(value='\\n    Creates augmented images for each input image in the image directory and saves them in the output directories.\\n    ')), Assign(targets=[Name(id='image_files', ctx=Store())], value=Call(func=Attribute(value=Name(id='os', ctx=Load()), attr='listdir', ctx=Load()), args=[Name(id='image_directory', ctx=Load())], keywords=[])), For(target=Name(id='image_file', ctx=Store()), iter=Name(id='image_files', ctx=Load()), body=[Assign(targets=[Name(id='input_image_jpg', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Name(id='image_directory', ctx=Load()), Name(id='image_file', ctx=Load())], keywords=[])), Assign(targets=[Name(id='input_text_txt', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Name(id='text_directory', ctx=Load()), JoinedStr(values=[FormattedValue(value=Subscript(value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='splitext', ctx=Load()), args=[Name(id='image_file', ctx=Load())], keywords=[]), slice=Constant(value=0), ctx=Load()), conversion=-1), Constant(value='.txt')])], keywords=[])), Assign(targets=[Name(id='img', ctx=Store())], value=Call(func=Attribute(value=Name(id='Image', ctx=Load()), attr='open', ctx=Load()), args=[Name(id='input_image_jpg', ctx=Load())], keywords=[])), For(target=Name(id='i', ctx=Store()), iter=Call(func=Name(id='range', ctx=Load()), args=[Name(id='num_images_per_input', ctx=Load())], keywords=[]), body=[Assign(targets=[Name(id='augmentation_choice', ctx=Store())], value=Call(func=Attribute(value=Name(id='random', ctx=Load()), attr='choice', ctx=Load()), args=[List(elts=[Constant(value='upside_down'), Constant(value='left_right'), Constant(value='noise'), Constant(value='grayscale'), Constant(value='saturation'), Constant(value='brightness'), Constant(value='contrast'), Constant(value='invert'), Constant(value='canny_edge'), Constant(value='blur')], ctx=Load())], keywords=[])), Assign(targets=[Name(id='output_image_path', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Name(id='output_image_directory', ctx=Load()), JoinedStr(values=[FormattedValue(value=Subscript(value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='splitext', ctx=Load()), args=[Name(id='image_file', ctx=Load())], keywords=[]), slice=Constant(value=0), ctx=Load()), conversion=-1), Constant(value='_'), FormattedValue(value=Name(id='i', ctx=Load()), conversion=-1), Constant(value='.jpg')])], keywords=[])), Assign(targets=[Name(id='output_text_path', ctx=Store())], value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='join', ctx=Load()), args=[Name(id='output_text_directory', ctx=Load()), JoinedStr(values=[FormattedValue(value=Subscript(value=Call(func=Attribute(value=Attribute(value=Name(id='os', ctx=Load()), attr='path', ctx=Load()), attr='splitext', ctx=Load()), args=[Name(id='image_file', ctx=Load())], keywords=[]), slice=Constant(value=0), ctx=Load()), conversion=-1), Constant(value='_'), FormattedValue(value=Name(id='i', ctx=Load()), conversion=-1), Constant(value='.txt')])], keywords=[])), If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='upside_down')]), body=[Expr(value=Call(func=Name(id='upside_down_augmentation', ctx=Load()), args=[Name(id='input_image_jpg', ctx=Load()), Name(id='input_text_txt', ctx=Load()), Name(id='output_image_path', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='left_right')]), body=[Expr(value=Call(func=Name(id='left_right_augmentation', ctx=Load()), args=[Name(id='input_image_jpg', ctx=Load()), Name(id='input_text_txt', ctx=Load()), Name(id='output_image_path', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='noise')]), body=[Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='add_noise', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='grayscale')]), body=[Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='convert_to_grayscale', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='saturation')]), body=[Assign(targets=[Name(id='saturation_factor', ctx=Store())], value=Call(func=Attribute(value=Name(id='random', ctx=Load()), attr='uniform', ctx=Load()), args=[Constant(value=0.5), Constant(value=1.5)], keywords=[])), Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='adjust_saturation', ctx=Load()), args=[Name(id='img', ctx=Load()), Name(id='saturation_factor', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='brightness')]), body=[Assign(targets=[Name(id='brightness_factor', ctx=Store())], value=Call(func=Attribute(value=Name(id='random', ctx=Load()), attr='uniform', ctx=Load()), args=[Constant(value=0.5), Constant(value=1.5)], keywords=[])), Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='adjust_brightness', ctx=Load()), args=[Name(id='img', ctx=Load()), Name(id='brightness_factor', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='contrast')]), body=[Assign(targets=[Name(id='contrast_factor', ctx=Store())], value=Call(func=Attribute(value=Name(id='random', ctx=Load()), attr='uniform', ctx=Load()), args=[Constant(value=0.5), Constant(value=1.5)], keywords=[])), Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='adjust_contrast', ctx=Load()), args=[Name(id='img', ctx=Load()), Name(id='contrast_factor', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='invert')]), body=[Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='invert_colors', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='canny_edge')]), body=[Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='apply_canny_edge_detection', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[If(test=Compare(left=Name(id='augmentation_choice', ctx=Load()), ops=[Eq()], comparators=[Constant(value='blur')]), body=[Assign(targets=[Name(id='augmented_img', ctx=Store())], value=Call(func=Name(id='apply_blur', ctx=Load()), args=[Name(id='img', ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id='augmented_img', ctx=Load()), attr='save', ctx=Load()), args=[Name(id='output_image_path', ctx=Load())], keywords=[])), Expr(value=Call(func=Name(id='copy_txt_file', ctx=Load()), args=[Name(id='input_text_txt', ctx=Load()), Name(id='output_text_path', ctx=Load())], keywords=[]))], orelse=[])])])])])])])])])])], orelse=[])], orelse=[])], decorator_list=[])\n",
            "File: /content/My-Projects/Foreign_Direct_Investment_Analytics.ipynb\n",
            "File: /content/My-Projects/Movie_Recommender_System.ipynb\n",
            "\n",
            "Search Results in /content/My-Projects/Amazon_SalesData_Analysis.ipynb: []\n",
            "\n",
            "Search Results in /content/My-Projects/Data-Preprocessing code.py: ['int']\n",
            "\n",
            "Search Results in /content/My-Projects/Steel_Rods_Counting_using_yolov8x_Client_Data.ipynb: []\n",
            "\n",
            "Search Results in /content/My-Projects/Deployment code.py: []\n",
            "\n",
            "Search Results in /content/My-Projects/bot.py: ['int']\n",
            "\n",
            "Search Results in /content/My-Projects/Object_Detection.ipynb: ['int', 'int', 'int', 'int', 'int', 'int']\n",
            "\n",
            "Search Results in /content/My-Projects/Manual_Augmentation_new_dataset.ipynb: ['int', 'int', 'int', 'int', 'int', 'int', 'int', 'int']\n",
            "\n",
            "Search Results in /content/My-Projects/Foreign_Direct_Investment_Analytics.ipynb: []\n",
            "\n",
            "Search Results in /content/My-Projects/Movie_Recommender_System.ipynb: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHa-XepAOuD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f39rniAAOuGl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}